{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\ndf = None\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        df = pd.read_csv(os.path.join(dirname, filename)).reset_index(drop=True)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"39dfb6d7-926b-436a-9336-fe998dd26976","_cell_guid":"6421d697-ea16-4779-9f70-2d82387819cb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-17T07:32:58.305142Z","iopub.execute_input":"2022-01-17T07:32:58.30569Z","iopub.status.idle":"2022-01-17T07:32:58.811528Z","shell.execute_reply.started":"2022-01-17T07:32:58.305495Z","shell.execute_reply":"2022-01-17T07:32:58.810614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:32:59.457814Z","iopub.execute_input":"2022-01-17T07:32:59.458397Z","iopub.status.idle":"2022-01-17T07:32:59.467883Z","shell.execute_reply.started":"2022-01-17T07:32:59.458363Z","shell.execute_reply":"2022-01-17T07:32:59.466657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:34.736116Z","iopub.execute_input":"2022-01-17T07:33:34.736427Z","iopub.status.idle":"2022-01-17T07:33:34.778561Z","shell.execute_reply.started":"2022-01-17T07:33:34.736395Z","shell.execute_reply":"2022-01-17T07:33:34.777656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_list  = ['*special problem', '2-sat', 'binary search', 'bitmasks',\n               'brute force', 'chinese remainder theorem', 'combinatorics',\n               'constructive algorithms', 'data structures', 'dfs and similar',\n               'divide and conquer', 'dp', 'dsu', 'expression parsing', 'fft', 'flows',\n               'games', 'geometry', 'graph matchings', 'graphs', 'greedy', 'hashing',\n               'implementation', 'interactive', 'math', 'matrices',\n               'meet-in-the-middle', 'number theory', 'probabilities', 'schedules',\n               'shortest paths', 'sortings', 'string suffix structures', 'strings',\n               'ternary search', 'trees', 'two pointers']","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:36.408765Z","iopub.execute_input":"2022-01-17T07:33:36.409503Z","iopub.status.idle":"2022-01-17T07:33:36.417264Z","shell.execute_reply.started":"2022-01-17T07:33:36.409459Z","shell.execute_reply":"2022-01-17T07:33:36.415945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(df.columns[0], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:37.725052Z","iopub.execute_input":"2022-01-17T07:33:37.725728Z","iopub.status.idle":"2022-01-17T07:33:37.73985Z","shell.execute_reply.started":"2022-01-17T07:33:37.725693Z","shell.execute_reply":"2022-01-17T07:33:37.738811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:39.242141Z","iopub.execute_input":"2022-01-17T07:33:39.243422Z","iopub.status.idle":"2022-01-17T07:33:39.250533Z","shell.execute_reply.started":"2022-01-17T07:33:39.243372Z","shell.execute_reply":"2022-01-17T07:33:39.249574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for tag in target_list:\n    df[tag] = df[tag].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:40.315041Z","iopub.execute_input":"2022-01-17T07:33:40.315799Z","iopub.status.idle":"2022-01-17T07:33:40.348263Z","shell.execute_reply.started":"2022-01-17T07:33:40.315763Z","shell.execute_reply":"2022-01-17T07:33:40.347403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:41.824763Z","iopub.execute_input":"2022-01-17T07:33:41.825067Z","iopub.status.idle":"2022-01-17T07:33:41.854038Z","shell.execute_reply.started":"2022-01-17T07:33:41.825036Z","shell.execute_reply":"2022-01-17T07:33:41.853048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[target_list].sum().sort_values().plot(kind=\"barh\", figsize=(10,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:47.001833Z","iopub.execute_input":"2022-01-17T07:33:47.00215Z","iopub.status.idle":"2022-01-17T07:33:47.715961Z","shell.execute_reply.started":"2022-01-17T07:33:47.00212Z","shell.execute_reply":"2022-01-17T07:33:47.714843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dropped_tag in target_list:\n    if df[dropped_tag].sum() <= 200:\n        df = df.drop(dropped_tag, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:48.776817Z","iopub.execute_input":"2022-01-17T07:33:48.777487Z","iopub.status.idle":"2022-01-17T07:33:48.81275Z","shell.execute_reply.started":"2022-01-17T07:33:48.777437Z","shell.execute_reply":"2022-01-17T07:33:48.811865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(\"*special problem\", axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:49.991261Z","iopub.execute_input":"2022-01-17T07:33:49.991556Z","iopub.status.idle":"2022-01-17T07:33:49.998529Z","shell.execute_reply.started":"2022-01-17T07:33:49.991524Z","shell.execute_reply":"2022-01-17T07:33:49.9975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_list = list(df.columns[1:])","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:51.293132Z","iopub.execute_input":"2022-01-17T07:33:51.293413Z","iopub.status.idle":"2022-01-17T07:33:51.298949Z","shell.execute_reply.started":"2022-01-17T07:33:51.293382Z","shell.execute_reply":"2022-01-17T07:33:51.297478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:33:52.762737Z","iopub.execute_input":"2022-01-17T07:33:52.763177Z","iopub.status.idle":"2022-01-17T07:33:52.785167Z","shell.execute_reply.started":"2022-01-17T07:33:52.763142Z","shell.execute_reply":"2022-01-17T07:33:52.783876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[target_list].sum().sort_values().plot(kind=\"barh\", figsize=(10,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:34:01.737148Z","iopub.execute_input":"2022-01-17T07:34:01.737459Z","iopub.status.idle":"2022-01-17T07:34:02.151435Z","shell.execute_reply.started":"2022-01-17T07:34:01.737429Z","shell.execute_reply":"2022-01-17T07:34:02.15047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na = []\nfor _ in df.iterrows():\n    if sum(_[1][target_list]) == 0:\n        na.append(_[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:36:02.28357Z","iopub.execute_input":"2022-01-17T07:36:02.283903Z","iopub.status.idle":"2022-01-17T07:36:07.055029Z","shell.execute_reply.started":"2022-01-17T07:36:02.283869Z","shell.execute_reply":"2022-01-17T07:36:07.054026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(na).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:36:52.553514Z","iopub.execute_input":"2022-01-17T07:36:52.554311Z","iopub.status.idle":"2022-01-17T07:36:52.562702Z","shell.execute_reply.started":"2022-01-17T07:36:52.55424Z","shell.execute_reply":"2022-01-17T07:36:52.561606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:36:59.599651Z","iopub.execute_input":"2022-01-17T07:36:59.599962Z","iopub.status.idle":"2022-01-17T07:36:59.622378Z","shell.execute_reply.started":"2022-01-17T07:36:59.599931Z","shell.execute_reply":"2022-01-17T07:36:59.621111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:05.082055Z","iopub.execute_input":"2022-01-17T07:37:05.082583Z","iopub.status.idle":"2022-01-17T07:37:05.098442Z","shell.execute_reply.started":"2022-01-17T07:37:05.082509Z","shell.execute_reply":"2022-01-17T07:37:05.097488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:24.204013Z","iopub.execute_input":"2022-01-17T07:37:24.204427Z","iopub.status.idle":"2022-01-17T07:37:35.223269Z","shell.execute_reply.started":"2022-01-17T07:37:24.204381Z","shell.execute_reply":"2022-01-17T07:37:35.222093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:35.226981Z","iopub.execute_input":"2022-01-17T07:37:35.227342Z","iopub.status.idle":"2022-01-17T07:37:37.150025Z","shell.execute_reply.started":"2022-01-17T07:37:35.227293Z","shell.execute_reply":"2022-01-17T07:37:37.148951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:37.155713Z","iopub.execute_input":"2022-01-17T07:37:37.15828Z","iopub.status.idle":"2022-01-17T07:37:43.41179Z","shell.execute_reply.started":"2022-01-17T07:37:37.15821Z","shell.execute_reply":"2022-01-17T07:37:43.410806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:43.413991Z","iopub.execute_input":"2022-01-17T07:37:43.414292Z","iopub.status.idle":"2022-01-17T07:37:49.162119Z","shell.execute_reply.started":"2022-01-17T07:37:43.414261Z","shell.execute_reply":"2022-01-17T07:37:49.161157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameters\nMAX_LEN = 256\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 1e-04\nn_classes = len(target_list)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:49.163485Z","iopub.execute_input":"2022-01-17T07:37:49.16424Z","iopub.status.idle":"2022-01-17T07:37:49.1715Z","shell.execute_reply.started":"2022-01-17T07:37:49.164192Z","shell.execute_reply":"2022-01-17T07:37:49.170286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.df = df\n        self.title = df['text']\n        self.targets = self.df[target_list].values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.title)\n\n    def __getitem__(self, index):\n        title = str(self.title[index])\n        title = \" \".join(title.split())\n\n        inputs = self.tokenizer.encode_plus(\n            title,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n            'targets': torch.FloatTensor(self.targets[index])\n        }","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:49.174311Z","iopub.execute_input":"2022-01-17T07:37:49.175807Z","iopub.status.idle":"2022-01-17T07:37:49.187215Z","shell.execute_reply.started":"2022-01-17T07:37:49.175707Z","shell.execute_reply":"2022-01-17T07:37:49.186227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = \"train.csv\"\ntest_path = \"test.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:37:49.189017Z","iopub.execute_input":"2022-01-17T07:37:49.190793Z","iopub.status.idle":"2022-01-17T07:37:49.200905Z","shell.execute_reply.started":"2022-01-17T07:37:49.190747Z","shell.execute_reply":"2022-01-17T07:37:49.199624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:6300].to_csv(\"train.csv\", index = False)\ndf[6300:].to_csv(\"test.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:01.48128Z","iopub.execute_input":"2022-01-17T07:38:01.481622Z","iopub.status.idle":"2022-01-17T07:38:02.067224Z","shell.execute_reply.started":"2022-01-17T07:38:01.481555Z","shell.execute_reply":"2022-01-17T07:38:02.066241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:04.913728Z","iopub.execute_input":"2022-01-17T07:38:04.914317Z","iopub.status.idle":"2022-01-17T07:38:05.100066Z","shell.execute_reply.started":"2022-01-17T07:38:04.914283Z","shell.execute_reply":"2022-01-17T07:38:05.099006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:07.510726Z","iopub.execute_input":"2022-01-17T07:38:07.51102Z","iopub.status.idle":"2022-01-17T07:38:07.51825Z","shell.execute_reply.started":"2022-01-17T07:38:07.510989Z","shell.execute_reply":"2022-01-17T07:38:07.516916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_df = df.sample(frac=train_size, random_state=42).reset_index(drop=True)\nval_df = df.drop(train_df.index).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:16.749823Z","iopub.execute_input":"2022-01-17T07:38:16.750679Z","iopub.status.idle":"2022-01-17T07:38:16.764781Z","shell.execute_reply.started":"2022-01-17T07:38:16.750645Z","shell.execute_reply":"2022-01-17T07:38:16.763594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, val_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:19.138912Z","iopub.execute_input":"2022-01-17T07:38:19.13922Z","iopub.status.idle":"2022-01-17T07:38:19.148934Z","shell.execute_reply.started":"2022-01-17T07:38:19.139191Z","shell.execute_reply":"2022-01-17T07:38:19.147808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[target_list].sum().sort_values().plot(kind=\"barh\", figsize=(10,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:23.024897Z","iopub.execute_input":"2022-01-17T07:38:23.025648Z","iopub.status.idle":"2022-01-17T07:38:23.428147Z","shell.execute_reply.started":"2022-01-17T07:38:23.025608Z","shell.execute_reply":"2022-01-17T07:38:23.427175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df[target_list].sum().sort_values().plot(kind=\"barh\", figsize=(10,10))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:45.423953Z","iopub.execute_input":"2022-01-17T07:38:45.424283Z","iopub.status.idle":"2022-01-17T07:38:45.799955Z","shell.execute_reply.started":"2022-01-17T07:38:45.424229Z","shell.execute_reply":"2022-01-17T07:38:45.798991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\nvalid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:50.405822Z","iopub.execute_input":"2022-01-17T07:38:50.40615Z","iopub.status.idle":"2022-01-17T07:38:50.417513Z","shell.execute_reply.started":"2022-01-17T07:38:50.406103Z","shell.execute_reply":"2022-01-17T07:38:50.415624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = torch.utils.data.DataLoader(train_dataset, \n    batch_size=TRAIN_BATCH_SIZE,\n    shuffle=True,\n    num_workers=0\n)\n\nval_data_loader = torch.utils.data.DataLoader(valid_dataset, \n    batch_size=VALID_BATCH_SIZE,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:52.486921Z","iopub.execute_input":"2022-01-17T07:38:52.487744Z","iopub.status.idle":"2022-01-17T07:38:52.496091Z","shell.execute_reply.started":"2022-01-17T07:38:52.487706Z","shell.execute_reply":"2022-01-17T07:38:52.49253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:38:54.70847Z","iopub.execute_input":"2022-01-17T07:38:54.709112Z","iopub.status.idle":"2022-01-17T07:38:54.764982Z","shell.execute_reply.started":"2022-01-17T07:38:54.709061Z","shell.execute_reply":"2022-01-17T07:38:54.763661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_ckp(checkpoint_fpath, model, optimizer):\n    \"\"\"\n    checkpoint_path: path to save checkpoint\n    model: model that we want to load checkpoint parameters into       \n    optimizer: optimizer we defined in previous training\n    \"\"\"\n    # load check point\n    checkpoint = torch.load(checkpoint_fpath)\n    # initialize state_dict from checkpoint to model\n    model.load_state_dict(checkpoint['state_dict'])\n    # initialize optimizer from checkpoint to optimizer\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    # return model, optimizer, epoch value, min validation loss \n    return model, optimizer, checkpoint['epoch']\n\ndef save_ckp(state, is_best, checkpoint_path, best_model_path):\n    \"\"\"\n    state: checkpoint we want to save\n    is_best: is this the best checkpoint; min validation loss\n    checkpoint_path: path to save checkpoint\n    best_model_path: path to save best model\n    \"\"\"\n    f_path = checkpoint_path\n    # save checkpoint data to the path given, checkpoint_path\n    torch.save(state, f_path)\n    # if it is a best model, min validation loss\n    if is_best:\n        best_fpath = best_model_path\n        # copy that checkpoint file to best path given, best_model_path\n        shutil.copyfile(f_path, best_fpath)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:39:03.867465Z","iopub.execute_input":"2022-01-17T07:39:03.868141Z","iopub.status.idle":"2022-01-17T07:39:03.877736Z","shell.execute_reply.started":"2022-01-17T07:39:03.868103Z","shell.execute_reply":"2022-01-17T07:39:03.876651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, n_classes)\n    \n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.bert_model(\n            input_ids, \n            attention_mask=attn_mask, \n            token_type_ids=token_type_ids\n        )\n        output_dropout = self.dropout(output.pooler_output)\n        output = self.linear(output_dropout)\n        return output\n\nmodel = BERTClass()\nmodel.to(device)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-17T07:39:06.565809Z","iopub.execute_input":"2022-01-17T07:39:06.566681Z","iopub.status.idle":"2022-01-17T07:39:29.8444Z","shell.execute_reply.started":"2022-01-17T07:39:06.566638Z","shell.execute_reply":"2022-01-17T07:39:29.843459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_pos_weights(class_counts):\n    pos_weights = np.ones_like(class_counts)\n    neg_counts = [len(train_df) - pos_count for pos_count in class_counts]\n    for cdx,(pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n        pos_weights[cdx] = len(train_df) / pos_count\n        \n    return torch.as_tensor(pos_weights, dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:39:29.846883Z","iopub.execute_input":"2022-01-17T07:39:29.847517Z","iopub.status.idle":"2022-01-17T07:39:29.854817Z","shell.execute_reply.started":"2022-01-17T07:39:29.84747Z","shell.execute_reply":"2022-01-17T07:39:29.853854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_counts = train_df[target_list].sum()\nclass_weights = calculate_pos_weights(class_counts).to(device)\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:39:29.85647Z","iopub.execute_input":"2022-01-17T07:39:29.856849Z","iopub.status.idle":"2022-01-17T07:39:29.947309Z","shell.execute_reply.started":"2022-01-17T07:39:29.856806Z","shell.execute_reply":"2022-01-17T07:39:29.946336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss(pos_weight=class_weights)(outputs, targets)\n\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:39:29.95096Z","iopub.execute_input":"2022-01-17T07:39:29.951313Z","iopub.status.idle":"2022-01-17T07:39:29.987117Z","shell.execute_reply.started":"2022-01-17T07:39:29.951198Z","shell.execute_reply":"2022-01-17T07:39:29.985516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_targets = []\nval_outputs = []","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:39:29.997729Z","iopub.execute_input":"2022-01-17T07:39:29.998035Z","iopub.status.idle":"2022-01-17T07:39:30.106987Z","shell.execute_reply.started":"2022-01-17T07:39:29.997993Z","shell.execute_reply":"2022-01-17T07:39:30.105819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:39:30.109514Z","iopub.execute_input":"2022-01-17T07:39:30.110328Z","iopub.status.idle":"2022-01-17T07:39:30.973054Z","shell.execute_reply.started":"2022-01-17T07:39:30.11028Z","shell.execute_reply":"2022-01-17T07:39:30.972074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_plot, valid_loss_plot, valid_acc_plot = [], [], []\ndef train_model(n_epochs, training_loader, validation_loader, model, \n                optimizer, checkpoint_path, best_model_path):\n   \n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf\n\n    for epoch in range(1, n_epochs + 1):\n        train_loss = 0\n        valid_loss = 0\n\n        model.train()\n        print(f'############# Epoch {epoch}: Training Start   #############')\n        for batch_idx, data in enumerate(training_loader):\n            # print('yyy epoch', batch_idx)\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n\n            outputs = model(ids, mask, token_type_ids)\n\n            optimizer.zero_grad()\n            loss = loss_fn(outputs, targets)\n            # if batch_idx%5000==0:\n            #     print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            #print('before loss data in training', loss.item(), train_loss)\n            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n            #print('after loss data in training', loss.item(), train_loss)\n    \n        print(f\"############# Epoch {epoch}: Training End     #############\")\n        \n        print(f\"############# Epoch {epoch}: Validation Start   #############\")\n        ######################    \n        # validate the model #\n        ######################\n    \n        model.eval()\n        \n        val_targets = []\n        val_outputs = []\n\n        with torch.no_grad():\n            for batch_idx, data in enumerate(validation_loader, 0):\n                ids = data['input_ids'].to(device, dtype = torch.long)\n                mask = data['attention_mask'].to(device, dtype = torch.long)\n                token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n                targets = data['targets'].to(device, dtype = torch.float)\n                outputs = model(ids, mask, token_type_ids)\n                \n                loss = loss_fn(outputs, targets)\n                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n                val_targets.extend(targets.cpu().detach().numpy().tolist())\n                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n\n            print(f'############# Epoch {epoch}: Validation End     #############')\n        # calculate average losses\n        #print('before cal avg train loss', train_loss)\n            train_loss = train_loss/len(training_loader)\n            valid_loss = valid_loss/len(validation_loader)\n        # print training/validation statistics \n            \n            val_outputs  = np.array(val_outputs)\n            val_targets = np.array(val_targets)\n            pred = np.array(val_outputs > 0.5).astype(np.float)\n            total_f1 = 0\n            for i, tag in enumerate(target_list):\n                total_f1 += f1_score(val_targets[:, i], pred[:, i])\n            total_f1 /= len(target_list)\n            \n            train_loss_plot.append(train_loss)\n            valid_loss_plot.append(valid_loss)\n            valid_acc_plot.append(total_f1)\n            \n            print(f'Epoch: {epoch} \\tAvgerage Training Loss: {train_loss:.6f} \\tAverage Validation Loss: {valid_loss:.6f} \\tAverage Accuracy(F1 score): {total_f1:.6f}')\n        \n        # create checkpoint variable and add important data\n            checkpoint = {\n                'epoch': epoch + 1,\n                'valid_loss_min': valid_loss,\n                'state_dict': model.state_dict(),\n                'optimizer': optimizer.state_dict()\n        }\n            \n            # save checkpoint\n            save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n            \n        ## TODO: save the model if validation loss has decreased\n            if valid_loss <= valid_loss_min:\n                print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n            # save checkpoint as best model\n                save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n                valid_loss_min = valid_loss\n\n        print(f'############# Epoch {epoch}  Done   #############\\n')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:40:07.003389Z","iopub.execute_input":"2022-01-17T07:40:07.004617Z","iopub.status.idle":"2022-01-17T07:40:07.05172Z","shell.execute_reply.started":"2022-01-17T07:40:07.004542Z","shell.execute_reply":"2022-01-17T07:40:07.048893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_path = \"curr_ckpt\"\nbest_model_path = \"best_model.pt\"","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:40:11.743194Z","iopub.execute_input":"2022-01-17T07:40:11.743483Z","iopub.status.idle":"2022-01-17T07:40:11.747942Z","shell.execute_reply.started":"2022-01-17T07:40:11.743453Z","shell.execute_reply":"2022-01-17T07:40:11.746774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T07:40:20.445338Z","iopub.execute_input":"2022-01-17T07:40:20.445692Z","iopub.status.idle":"2022-01-17T09:04:24.231184Z","shell.execute_reply.started":"2022-01-17T07:40:20.445658Z","shell.execute_reply":"2022-01-17T09:04:24.230144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:04:24.242253Z","iopub.execute_input":"2022-01-17T09:04:24.242647Z","iopub.status.idle":"2022-01-17T09:04:24.253074Z","shell.execute_reply.started":"2022-01-17T09:04:24.242553Z","shell.execute_reply":"2022-01-17T09:04:24.25198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_loss_plot, label=\"train loss\")\nplt.plot(valid_loss_plot, label=\"validation loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:04:24.258385Z","iopub.execute_input":"2022-01-17T09:04:24.261218Z","iopub.status.idle":"2022-01-17T09:04:25.177892Z","shell.execute_reply.started":"2022-01-17T09:04:24.261167Z","shell.execute_reply":"2022-01-17T09:04:25.176977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(valid_acc_plot)\nplt.ylabel(\"Validation accuracy (F1 score)\")\nplt.xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:04:25.180323Z","iopub.execute_input":"2022-01-17T09:04:25.181154Z","iopub.status.idle":"2022-01-17T09:04:26.34463Z","shell.execute_reply.started":"2022-01-17T09:04:25.181089Z","shell.execute_reply":"2022-01-17T09:04:26.343424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = []\nfor test_case in range(len(test_df)):\n    example = test_df['text'][test_case]\n    encodings = tokenizer.encode_plus(\n        example,\n        None,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding='max_length',\n        return_token_type_ids=True,\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    model.eval()\n    \n    with torch.no_grad():\n        input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n        attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n        token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n        output = model(input_ids, attention_mask, token_type_ids)\n        final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n        pred.append(final_output[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:04:26.346374Z","iopub.execute_input":"2022-01-17T09:04:26.351303Z","iopub.status.idle":"2022-01-17T09:04:48.516489Z","shell.execute_reply.started":"2022-01-17T09:04:26.350498Z","shell.execute_reply":"2022-01-17T09:04:48.515492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.array(np.array(pred) > 0.5).astype(np.float)\nanswer = np.array(test_df[target_list]).astype(np.float)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:04:58.30908Z","iopub.execute_input":"2022-01-17T09:04:58.309493Z","iopub.status.idle":"2022-01-17T09:04:58.324412Z","shell.execute_reply.started":"2022-01-17T09:04:58.309461Z","shell.execute_reply":"2022-01-17T09:04:58.322879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_f1 = 0\nfor i, tag in enumerate(target_list):\n    tag_f1_score = f1_score(answer[:, i], pred[:, i])\n    test_f1 += tag_f1_score\n    print(f\"F1 score of {tag} tag: {tag_f1_score}\")\ntest_f1 /= len(target_list)\nprint(f\"Test accuracy: {test_f1}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:04:59.351927Z","iopub.execute_input":"2022-01-17T09:04:59.352441Z","iopub.status.idle":"2022-01-17T09:04:59.428607Z","shell.execute_reply.started":"2022-01-17T09:04:59.352406Z","shell.execute_reply":"2022-01-17T09:04:59.427672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = \"\"\"\nGiven a list of D digits and an integer K, we consider all different ways to permute these digits\ninto a D-digit decimal number. The target of this problem is to find a permutation X, such\nthat when X is divided by K, the remainder (between 0 and K − 1) is the largest among\nall other permutations. If there are more than one possible permutation, output the largest\npermutation.\nFor instance, suppose that we have D = 3 digits, and they are respectively 1, 2, 3.\n1. If K = 1, then we see that every permutation will give a remainder 0 when divided by K,\nand 321 is thus the desired answer, as it is the largest permutation among all.\n2. If K = 10, then both 123 and 213 will give a remainder 3 when divided by K, and this is\nthe largest possible remainder in this case. Consequently, the desired output is 213 since\nit is a larger permutation.\n3. If K = 100, then the largest remainder we can get is 32, when the permutation is 132.\nInput Format\nThe first line of the input contains a positive integer D followed by a positive integer K. Then,\nthe next line contains D digits, each digit d has value 1 ≤ d ≤ 9 and is separated from the next\none by a space.\nOutput Format\nOutput the largest permutation that gives the largest remainder in a single line.\nTechnical Specification\n∙ 1 ≤ D ≤ 16\n∙ 1 ≤ K ≤ 200\n∙ 1 ≤ d ≤ 9\n\"\"\"\nencodings = tokenizer.encode_plus(\n    example,\n    None,\n    add_special_tokens=True,\n    max_length=MAX_LEN,\n    padding='max_length',\n    return_token_type_ids=True,\n    truncation=True,\n    return_attention_mask=True,\n    return_tensors='pt'\n)\nmodel.eval()\nwith torch.no_grad():\n    input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n    attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n    token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n    output = model(input_ids, attention_mask, token_type_ids)\n    final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n    print(f\"Tags for the problem: \")\n    for i, prob in enumerate(final_output[0]):\n        if prob >= 0.5:\n            print(f\"{target_list[i]}({round(prob*100, 2)}%)\", end=' ')\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:10:09.54694Z","iopub.execute_input":"2022-01-17T09:10:09.547232Z","iopub.status.idle":"2022-01-17T09:10:09.58826Z","shell.execute_reply.started":"2022-01-17T09:10:09.5472Z","shell.execute_reply":"2022-01-17T09:10:09.58726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = BERTClass()\nbest_model.to(device)\nbest_optimize = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\nbest_model, best_optimize, best_epoch = load_ckp(\"best_model.pt\", best_model, best_optimize)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:05:20.744451Z","iopub.execute_input":"2022-01-17T09:05:20.74516Z","iopub.status.idle":"2022-01-17T09:05:26.118472Z","shell.execute_reply.started":"2022-01-17T09:05:20.745104Z","shell.execute_reply":"2022-01-17T09:05:26.117416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = []\nfor test_case in range(len(test_df)):\n    example = test_df['text'][test_case]\n    encodings = tokenizer.encode_plus(\n        example,\n        None,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding='max_length',\n        return_token_type_ids=True,\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    best_model.eval()\n    \n    with torch.no_grad():\n        input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n        attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n        token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n        output = best_model(input_ids, attention_mask, token_type_ids)\n        final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n        pred.append(final_output[0])\n        \npred = np.array(np.array(pred) > 0.5).astype(np.float)\nanswer = np.array(test_df[target_list]).astype(np.float)\n\ntest_f1 = 0\nfor i, tag in enumerate(target_list):\n    tag_f1_score = f1_score(answer[:, i], pred[:, i])\n    test_f1 += tag_f1_score\n    print(f\"F1 score of {tag} tag: {tag_f1_score}\")\ntest_f1 /= len(target_list)\nprint(f\"Test accuracy: {test_f1}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:05:30.693551Z","iopub.execute_input":"2022-01-17T09:05:30.693889Z","iopub.status.idle":"2022-01-17T09:05:52.496754Z","shell.execute_reply.started":"2022-01-17T09:05:30.693848Z","shell.execute_reply":"2022-01-17T09:05:52.495783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = \"\"\"\nGiven a list of D digits and an integer K, we consider all different ways to permute these digits\ninto a D-digit decimal number. The target of this problem is to find a permutation X, such\nthat when X is divided by K, the remainder (between 0 and K − 1) is the largest among\nall other permutations. If there are more than one possible permutation, output the largest\npermutation.\nFor instance, suppose that we have D = 3 digits, and they are respectively 1, 2, 3.\n1. If K = 1, then we see that every permutation will give a remainder 0 when divided by K,\nand 321 is thus the desired answer, as it is the largest permutation among all.\n2. If K = 10, then both 123 and 213 will give a remainder 3 when divided by K, and this is\nthe largest possible remainder in this case. Consequently, the desired output is 213 since\nit is a larger permutation.\n3. If K = 100, then the largest remainder we can get is 32, when the permutation is 132.\nInput Format\nThe first line of the input contains a positive integer D followed by a positive integer K. Then,\nthe next line contains D digits, each digit d has value 1 ≤ d ≤ 9 and is separated from the next\none by a space.\nOutput Format\nOutput the largest permutation that gives the largest remainder in a single line.\nTechnical Specification\n∙ 1 ≤ D ≤ 16\n∙ 1 ≤ K ≤ 200\n∙ 1 ≤ d ≤ 9\n\"\"\"\nencodings = tokenizer.encode_plus(\n    example,\n    None,\n    add_special_tokens=True,\n    max_length=MAX_LEN,\n    padding='max_length',\n    return_token_type_ids=True,\n    truncation=True,\n    return_attention_mask=True,\n    return_tensors='pt'\n)\nbest_model.eval()\nwith torch.no_grad():\n    input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n    attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n    token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n    output = best_model(input_ids, attention_mask, token_type_ids)\n    final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n    print(f\"Tags for the problem: \")\n    for i, prob in enumerate(final_output[0]):\n        if prob >= 0.5:\n            print(f\"{target_list[i]}({round(prob*100, 2)}%)\", end=' ')\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:09:56.421275Z","iopub.execute_input":"2022-01-17T09:09:56.421561Z","iopub.status.idle":"2022-01-17T09:09:56.464235Z","shell.execute_reply.started":"2022-01-17T09:09:56.42153Z","shell.execute_reply":"2022-01-17T09:09:56.463246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = \"\"\"\nfind the probability of rolling a die\n\"\"\"\nencodings = tokenizer.encode_plus(\n    example,\n    None,\n    add_special_tokens=True,\n    max_length=MAX_LEN,\n    padding='max_length',\n    return_token_type_ids=True,\n    truncation=True,\n    return_attention_mask=True,\n    return_tensors='pt'\n)\nbest_model.eval()\nwith torch.no_grad():\n    input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n    attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n    token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n    output = best_model(input_ids, attention_mask, token_type_ids)\n    final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n    print(f\"Tags for the problem: \")\n    for i, prob in enumerate(final_output[0]):\n        if prob >= 0.5:\n            print(f\"{target_list[i]}({round(prob*100, 2)}%)\", end=' ')\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T09:09:39.819355Z","iopub.execute_input":"2022-01-17T09:09:39.819667Z","iopub.status.idle":"2022-01-17T09:09:39.849653Z","shell.execute_reply.started":"2022-01-17T09:09:39.819633Z","shell.execute_reply":"2022-01-17T09:09:39.848659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}